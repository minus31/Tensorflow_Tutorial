{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network \n",
    "\n",
    "## Learning by implementation\n",
    "\n",
    "* **flow**\n",
    "\n",
    "1. Reading dataset (TFRecord)\n",
    "2. Building CNN\n",
    "    > ReLU\n",
    "   \n",
    "   * Convolution layer \n",
    "       $$h^n = ReLU(W^T_{n-1} * h^{n-1}) + b$$\n",
    "   * CNN에서 바뀐 것 \n",
    "     - matmul > Convolution\n",
    "     - sigmoid activation > ReLU activation (for improve performance)\n",
    "   \n",
    "3. Applying Dropout layer\n",
    "  > 매 train step 마다 랜덤하게 정해준 비율 만큼의 노드를 제외 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MAC/.pyenv/versions/anaconda3-5.0.1/envs/python_ana/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser for TFRecord\n",
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'age' : tf.FixedLenFeature([1], tf.int64),\n",
    "        'img' : tf.FixedLenFeature([61*49], tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    age = parsed_feature['age']\n",
    "    img = parsed_feature['img']\n",
    "    return age, img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "face_train = \"./cnn_dataset/face_train.tfrecord\"\n",
    "face_test = \"./cnn_dataset/face_test.tfrecord\"\n",
    "\n",
    "# Dataset\n",
    "train_dataset = tf.data.TFRecordDataset(face_train).map(parser)\n",
    "train_dataset = train_dataset.batch(32).shuffle(777)\n",
    "test_dataset = tf.data.TFRecordDataset(face_test).map(parser)\n",
    "test_dataset = test_dataset.batch(32).shuffle(777)\n",
    "\n",
    "\n",
    "#새로운 Iterator\n",
    "# Basically, dtype and shape have to be share with same value to both train and test datasets\n",
    "itr = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "age, img = itr.get_next()\n",
    "\n",
    "img = tf.reshape(img, [-1, 61, 49, 1]) # 차원 주의 !\n",
    "img = tf.cast(img, tf.float32)\n",
    "\n",
    "age = tf.reshape(age, [-1]) # 차원 주의 ! \n",
    "age_ohe = tf.one_hot(age, depth=3, axis=-1)\n",
    "\n",
    "train_init_op = itr.make_initializer(train_dataset)\n",
    "test_init_op = itr.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name var conv1/kernel:0 is illegal; using var_conv1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name var conv1/bias:0 is illegal; using var_conv1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name var conv2/kernel:0 is illegal; using var_conv2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name var conv2/bias:0 is illegal; using var_conv2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name var conv3/kernel:0 is illegal; using var_conv3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name var conv3/bias:0 is illegal; using var_conv3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name var fc1/kernel:0 is illegal; using var_fc1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name var fc1/bias:0 is illegal; using var_fc1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name var out/kernel:0 is illegal; using var_out/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name var out/bias:0 is illegal; using var_out/bias_0 instead.\n"
     ]
    }
   ],
   "source": [
    "def model(x, activation, dropout_prob, reuse=False):\n",
    "    # 10개의 feature map, 3x3 필터사이즈 \n",
    "    conv1 = tf.layers.conv2d(img, filters=16, kernel_size=3, \n",
    "                             padding='SAME', activation=activation, \n",
    "                             reuse=reuse, name='conv1')\n",
    "    # 2x2 maxpooling stride=2 \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=16, kernel_size=3,\n",
    "                            padding=\"SAME\", activation=activation,\n",
    "                            reuse=reuse, name='conv2')\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(pool2, filters=32, kernel_size=3, \n",
    "                            padding=\"SAME\", activation=activation,\n",
    "                            reuse=reuse, name='conv3')\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, pool_size=3, strides=2)\n",
    "    # flattening for going through \n",
    "    flat_size = int(pool3.shape[1]) * int(pool3.shape[2]) * int(pool3.shape[3])\n",
    "    flat = tf.reshape(pool3, [-1, flat_size])\n",
    "    # # or\n",
    "    # flat = tf.layers.flatten(pool3)\n",
    "    \n",
    "    dropout1 = tf.layers.dropout(flat, rate=dropout_prob)\n",
    "    fc1 = tf.layers.dense(dropout1, units=1000, reuse=reuse, \n",
    "                          name='fc1')\n",
    "\n",
    "    dropout2 = tf.layers.dropout(fc1, rate=dropout_prob)\n",
    "    out = tf.layers.dense(dropout2, 3, reuse=reuse, name='out')\n",
    "    \n",
    "    return out \n",
    "\n",
    "train_out = model(img, tf.nn.relu, 0.7)\n",
    "test_out = model(img, tf.nn.relu, 1, True)\n",
    "\n",
    "# 여기서도 loss 에서 소프트맥스를 구해준다.\n",
    "loss = tf.losses.softmax_cross_entropy(age_ohe, train_out)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-4).minimize=(loss)\n",
    "summary = tf.summary.scalar('train_loss', loss)\n",
    "\n",
    "pred = tf.argmax(tf.nn.softmax(test_out), axis=1)\n",
    "accuracy = tf.metrics.accuracy(age, pred)\n",
    "\n",
    "\n",
    "# prediction \n",
    "train_pred = tf.nn.softmax(train_out)\n",
    "test_pred = tf.nn.softmax(test_out)\n",
    "test_pred = tf.argmax(test_pred, axis=1)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram('var {}'.format(var.name), var)\n",
    "    \n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs : 0, train_loss : 17.21306610107422, acc : 0.3211192488670349\n",
      "epochs : 1, train_loss : 13.23499584197998, acc : 0.3180619776248932\n",
      "epochs : 2, train_loss : 19.477638244628906, acc : 0.3148675262928009\n",
      "epochs : 3, train_loss : 41.07842254638672, acc : 0.3173770606517792\n",
      "epochs : 4, train_loss : 42.93489456176758, acc : 0.31743744015693665\n",
      "epochs : 5, train_loss : 26.506134033203125, acc : 0.31693214178085327\n",
      "epochs : 6, train_loss : 34.25714874267578, acc : 0.3174128532409668\n",
      "epochs : 7, train_loss : 17.400615692138672, acc : 0.3167102634906769\n",
      "epochs : 8, train_loss : 32.453163146972656, acc : 0.3169633150100708\n",
      "epochs : 9, train_loss : 39.122859954833984, acc : 0.3172309994697571\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('cnn_dataset/', sess.graph)\n",
    "    loss_pdf = []\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        sess.run(train_init_op)\n",
    "        for train_step in range(9999999):\n",
    "            try :\n",
    "                _, _loss, _summ = sess.run([train_op, loss, summary])\n",
    "                loss_pdf.append(_loss)\n",
    "                writer.add_summary(_summ, train_step)\n",
    "                    \n",
    "            except tf.errors.OutOfRangeError :\n",
    "                break\n",
    "        sess.run(test_init_op)\n",
    "        for test_step in range(99999999):\n",
    "                try:\n",
    "                    _acc = sess.run(accuracy)\n",
    "                    \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "        print('epochs : {}, train_loss : {}, acc : {}'.format(epoch, _loss, _acc[0]))\n",
    "        saver.save(sess, \"./cnn_dataset/cnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
